{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMBb0aNQl8+lKeHRniNEMio",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John1495/RNA-3D/blob/main/GCNConv_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV3QVniXWiak"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RlCUQK7PPYNG",
        "outputId": "177b5137-b658-432a-ee68-52ed366fa9b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
            "  Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
            "  Downloading greenlet-3.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading greenlet-3.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (583 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.9/583.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: greenlet, colorlog, sqlalchemy, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 greenlet-3.2.1 optuna-4.3.0 sqlalchemy-2.0.40\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "!pip install joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9yyx52fhPl8b",
        "outputId": "4ba84ab5-2dac-42da-e786-df9ae57d4273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_scatter-2.1.2%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (500 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.4/500.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_sparse-0.6.18%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_cluster-1.6.3%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (753 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.3/210.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed torch-cluster-1.6.3+pt21cpu torch-geometric-2.6.1 torch-scatter-2.1.2+pt21cpu torch-sparse-0.6.18+pt21cpu torch-spline-conv-1.2.2+pt21cpu\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load data\n",
        "seq_df = pd.read_csv('/kaggle/cleaned_train_sequences2 (1).csv')\n",
        "label_df = pd.read_csv('/kaggle/train_labels1.csv')\n",
        "label_df['resname'] = label_df['resname'].str.extract(r'([AUGC])')\n",
        "label_df = label_df.dropna(subset=['resname'])\n",
        "label_df['target_id'] = label_df['ID'].str.extract(r'(.+)_\\d+')\n",
        "merged = pd.merge(label_df, seq_df[['target_id', 'sequence']], on='target_id', how='left')\n",
        "\n",
        "# Filter complete cases only\n",
        "complete_ids = merged.groupby('target_id')['resid'].count()\n",
        "valid_ids = complete_ids[complete_ids > 10].index\n",
        "merged = merged[merged['target_id'].isin(valid_ids)]\n",
        "\n",
        "# Train-validation split\n",
        "all_ids = merged['target_id'].unique()\n",
        "train_ids, val_ids = train_test_split(all_ids, test_size=0.1, random_state=42)\n",
        "\n",
        "residue_mapping = {'A': 0, 'U': 1, 'G': 2, 'C': 3}\n",
        "\n",
        "def create_graph_from_group(df_group, scaler=None, fit_scaler=False):\n",
        "    sequence = df_group['sequence'].values[0]\n",
        "    coords = df_group[['x_1', 'y_1', 'z_1']].values\n",
        "    df_group = df_group.sort_values('resid')\n",
        "    node_features = torch.eye(4)[[residue_mapping[r] for r in df_group['resname']]]\n",
        "\n",
        "    if scaler is not None:\n",
        "        if fit_scaler:\n",
        "            coords = scaler.fit_transform(coords)\n",
        "        else:\n",
        "            coords = scaler.transform(coords)\n",
        "\n",
        "    pos = torch.tensor(coords, dtype=torch.float)\n",
        "    y = pos  # predict absolute coordinates\n",
        "\n",
        "    n = len(df_group)\n",
        "    edge_index = torch.tensor(\n",
        "        [[i, i+1] for i in range(n-1)] + [[i+1, i] for i in range(n-1)],\n",
        "        dtype=torch.long\n",
        "    ).t().contiguous()\n",
        "\n",
        "    return Data(x=node_features, edge_index=edge_index, pos=pos, y=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_graphs, val_graphs = [], []\n",
        "for tid in tqdm(train_ids):\n",
        "    g = create_graph_from_group(merged[merged['target_id'] == tid], scaler, fit_scaler=True)\n",
        "    train_graphs.append(g)\n",
        "\n",
        "for tid in tqdm(val_ids):\n",
        "    g = create_graph_from_group(merged[merged['target_id'] == tid], scaler, fit_scaler=False)\n",
        "    val_graphs.append(g)\n",
        "\n",
        "train_loader = DataLoader(train_graphs, batch_size=1)\n",
        "val_loader = DataLoader(val_graphs, batch_size=1)\n",
        "\n",
        "class GCNNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GCNNet, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCNNet(input_dim=4, hidden_dim=32, output_dim=3).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience = 10\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(batch)\n",
        "        loss = loss_fn(pred, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch}, Loss: {avg_loss:.6f}\")\n",
        "\n",
        "    if avg_loss < best_val_loss:\n",
        "        best_val_loss = avg_loss\n",
        "        epochs_without_improvement = 0\n",
        "        torch.save(model.state_dict(), \"MODEL_GCN.pth\")\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "model.eval()\n",
        "predictions, true = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(batch)\n",
        "        predictions.append(pred.cpu().numpy())\n",
        "        true.append(batch.y.cpu().numpy())\n",
        "\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true = np.concatenate(true, axis=0)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(true, predictions))\n",
        "mae = mean_absolute_error(true, predictions)\n",
        "\n",
        "def calculate_tm_score(true, pred):\n",
        "    d = np.linalg.norm(true - pred, axis=1)\n",
        "    N = true.shape[0]\n",
        "    return np.mean(np.exp(-d / (0.5 * N)))\n",
        "\n",
        "def calculate_rmsd(true, pred):\n",
        "    return np.sqrt(np.mean((true - pred) ** 2))\n",
        "\n",
        "tm_score = calculate_tm_score(true, predictions)\n",
        "rmsd = calculate_rmsd(true, predictions)\n",
        "\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"RMSE: {rmse:.6f}\")\n",
        "print(f\"MAE: {mae:.6f}\")\n",
        "print(f\"TM-Score: {tm_score:.6f}\")\n",
        "print(f\"RMSD: {rmsd:.6f}\")\n",
        "\n",
        "# Save scaler\n",
        "joblib.dump(scaler, \"scaler_gcn.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQXL-FQpWmGZ",
        "outputId": "6c2d7572-8cd4-41ea-c5d8-96a23e0f7172"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
            "100%|██████████| 747/747 [00:07<00:00, 96.00it/s]\n",
            "100%|██████████| 83/83 [00:00<00:00, 97.12it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.950368\n",
            "Epoch 1, Loss: 0.948379\n",
            "Epoch 2, Loss: 0.948051\n",
            "Epoch 3, Loss: 0.947850\n",
            "Epoch 4, Loss: 0.947716\n",
            "Epoch 5, Loss: 0.947637\n",
            "Epoch 6, Loss: 0.947593\n",
            "Epoch 7, Loss: 0.947563\n",
            "Epoch 8, Loss: 0.947533\n",
            "Epoch 9, Loss: 0.947516\n",
            "Epoch 10, Loss: 0.947484\n",
            "Epoch 11, Loss: 0.947457\n",
            "Epoch 12, Loss: 0.947419\n",
            "Epoch 13, Loss: 0.947412\n",
            "Epoch 14, Loss: 0.947384\n",
            "Epoch 15, Loss: 0.947383\n",
            "Epoch 16, Loss: 0.947354\n",
            "Epoch 17, Loss: 0.947365\n",
            "Epoch 18, Loss: 0.947334\n",
            "Epoch 19, Loss: 0.947318\n",
            "Epoch 20, Loss: 0.947293\n",
            "Epoch 21, Loss: 0.947303\n",
            "Epoch 22, Loss: 0.947270\n",
            "Epoch 23, Loss: 0.947272\n",
            "Epoch 24, Loss: 0.947252\n",
            "Epoch 25, Loss: 0.947234\n",
            "Epoch 26, Loss: 0.947231\n",
            "Epoch 27, Loss: 0.947212\n",
            "Epoch 28, Loss: 0.947209\n",
            "Epoch 29, Loss: 0.947191\n",
            "Epoch 30, Loss: 0.947196\n",
            "Epoch 31, Loss: 0.947171\n",
            "Epoch 32, Loss: 0.947168\n",
            "Epoch 33, Loss: 0.947153\n",
            "Epoch 34, Loss: 0.947139\n",
            "Epoch 35, Loss: 0.947145\n",
            "Epoch 36, Loss: 0.947125\n",
            "Epoch 37, Loss: 0.947118\n",
            "Epoch 38, Loss: 0.947110\n",
            "Epoch 39, Loss: 0.947101\n",
            "Epoch 40, Loss: 0.947097\n",
            "Epoch 41, Loss: 0.947090\n",
            "Epoch 42, Loss: 0.947078\n",
            "Epoch 43, Loss: 0.947080\n",
            "Epoch 44, Loss: 0.947071\n",
            "Epoch 45, Loss: 0.947065\n",
            "Epoch 46, Loss: 0.947058\n",
            "Epoch 47, Loss: 0.947053\n",
            "Epoch 48, Loss: 0.947052\n",
            "Epoch 49, Loss: 0.947051\n",
            "Epoch 50, Loss: 0.947041\n",
            "Epoch 51, Loss: 0.947038\n",
            "Epoch 52, Loss: 0.947036\n",
            "Epoch 53, Loss: 0.947029\n",
            "Epoch 54, Loss: 0.947027\n",
            "Epoch 55, Loss: 0.947025\n",
            "Epoch 56, Loss: 0.947020\n",
            "Epoch 57, Loss: 0.947015\n",
            "Epoch 58, Loss: 0.947012\n",
            "Epoch 59, Loss: 0.947012\n",
            "Epoch 60, Loss: 0.947008\n",
            "Epoch 61, Loss: 0.947006\n",
            "Epoch 62, Loss: 0.947004\n",
            "Epoch 63, Loss: 0.947004\n",
            "Epoch 64, Loss: 0.946995\n",
            "Epoch 65, Loss: 0.946995\n",
            "Epoch 66, Loss: 0.946998\n",
            "Epoch 67, Loss: 0.946997\n",
            "Epoch 68, Loss: 0.946996\n",
            "Epoch 69, Loss: 0.946990\n",
            "Epoch 70, Loss: 0.946993\n",
            "Epoch 71, Loss: 0.946988\n",
            "Epoch 72, Loss: 0.946990\n",
            "Epoch 73, Loss: 0.946987\n",
            "Epoch 74, Loss: 0.946988\n",
            "Epoch 75, Loss: 0.946986\n",
            "Epoch 76, Loss: 0.946989\n",
            "Epoch 77, Loss: 0.946982\n",
            "Epoch 78, Loss: 0.946983\n",
            "Epoch 79, Loss: 0.946980\n",
            "Epoch 80, Loss: 0.946980\n",
            "Epoch 81, Loss: 0.946979\n",
            "Epoch 82, Loss: 0.946981\n",
            "Epoch 83, Loss: 0.946982\n",
            "Epoch 84, Loss: 0.946976\n",
            "Epoch 85, Loss: 0.946977\n",
            "Epoch 86, Loss: 0.946978\n",
            "Epoch 87, Loss: 0.946973\n",
            "Epoch 88, Loss: 0.946973\n",
            "Epoch 89, Loss: 0.946963\n",
            "Epoch 90, Loss: 0.946958\n",
            "Epoch 91, Loss: 0.946959\n",
            "Epoch 92, Loss: 0.946948\n",
            "Epoch 93, Loss: 0.946955\n",
            "Epoch 94, Loss: 0.946946\n",
            "Epoch 95, Loss: 0.946948\n",
            "Epoch 96, Loss: 0.946947\n",
            "Epoch 97, Loss: 0.946948\n",
            "Epoch 98, Loss: 0.946944\n",
            "Epoch 99, Loss: 0.946943\n",
            "\n",
            "Validation Metrics:\n",
            "RMSE: 27.461391\n",
            "MAE: 21.324112\n",
            "TM-Score: 0.994987\n",
            "RMSD: 27.461397\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler_gcn.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Then save it to your drive\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/GCNConv_Model.pth')\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/GCNConc_Scaler.save')\n",
        "\n",
        "print(\"Saved to Google Drive as 'GCNConv_Model.pth'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PMXnbRtYXon",
        "outputId": "83d83edd-1f41-4a99-b227-42e6737d36de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Saved to Google Drive as 'GCNConv_Model.pth'\n"
          ]
        }
      ]
    }
  ]
}