{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyO9gDrF4vwjufA2ONxzpS/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John1495/RNA-3D/blob/main/GVP_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G-76ER7QI-SW",
        "outputId": "ccfb1cd4-351e-4cac-9d41-23a9aaef79d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrFzuY-sDzCv",
        "outputId": "32a78b4a-b35f-4b41-ef6b-7934f164ff79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_scatter-2.1.2%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (500 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.4/500.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_sparse-0.6.18%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_cluster-1.6.3%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (753 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.3/210.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed torch-cluster-1.6.3+pt21cpu torch-geometric-2.6.1 torch-scatter-2.1.2+pt21cpu torch-sparse-0.6.18+pt21cpu torch-spline-conv-1.2.2+pt21cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tqdm import tqdm\n",
        "\n",
        "# == Load Data ==\n",
        "seq_df = pd.read_csv('/kaggle/cleaned_train_sequences2 (1).csv')\n",
        "label_df = pd.read_csv('/kaggle/train_labels1.csv')\n",
        "\n",
        "label_df['resname'] = label_df['resname'].str.extract(r'([AUGC])')\n",
        "label_df = label_df.dropna(subset=['resname'])\n",
        "label_df['target_id'] = label_df['ID'].str.extract(r'(.+)_\\d+')\n",
        "\n",
        "merged = pd.merge(label_df, seq_df[['target_id', 'sequence']], on='target_id', how='left')\n",
        "\n",
        "# Filter for complete RNAs\n",
        "valid_ids = merged.groupby('target_id')['resid'].count()\n",
        "valid_ids = valid_ids[valid_ids > 10].index\n",
        "merged = merged[merged['target_id'].isin(valid_ids)]\n",
        "\n",
        "train_ids, val_ids = train_test_split(merged['target_id'].unique(), test_size=0.1, random_state=42)\n",
        "residue_mapping = {'A': 0, 'U': 1, 'G': 2, 'C': 3}\n",
        "\n",
        "# == Graph Creator ==\n",
        "def create_graph(df_group, scaler=None, fit_scaler=False):\n",
        "    df_group = df_group.sort_values('resid')\n",
        "    coords = df_group[['x_1', 'y_1', 'z_1']].values\n",
        "\n",
        "    if scaler:\n",
        "        coords = scaler.fit_transform(coords) if fit_scaler else scaler.transform(coords)\n",
        "\n",
        "    node_scalar = torch.eye(4)[[residue_mapping[r] for r in df_group['resname']]]\n",
        "\n",
        "    # Vector features are placeholder zeros for now (can be enhanced)\n",
        "    node_vector = torch.zeros((len(df_group), 4))\n",
        "\n",
        "    node_features = torch.cat([node_scalar, node_vector], dim=1)\n",
        "\n",
        "    pos = torch.tensor(coords, dtype=torch.float)\n",
        "    y = pos\n",
        "    n = len(df_group)\n",
        "\n",
        "    edge_index = torch.tensor([[i, j] for i in range(n) for j in range(n) if i != j], dtype=torch.long).t().contiguous()\n",
        "    return Data(x=node_features, edge_index=edge_index, pos=pos, y=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_graphs = [create_graph(merged[merged['target_id'] == tid], scaler, True) for tid in tqdm(train_ids)]\n",
        "val_graphs = [create_graph(merged[merged['target_id'] == tid], scaler, False) for tid in tqdm(val_ids)]\n",
        "\n",
        "train_loader = DataLoader(train_graphs, batch_size=1)\n",
        "val_loader = DataLoader(val_graphs, batch_size=1)\n",
        "\n",
        "# == GVP Block ==\n",
        "class GVPBlock(nn.Module):\n",
        "    def __init__(self, scalar_dim, vector_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.scalar_mlp = nn.Sequential(\n",
        "            nn.Linear(scalar_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.vector_mlp = nn.Sequential(\n",
        "            nn.Linear(vector_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_scalar, x_vector):\n",
        "        s_out = self.scalar_mlp(x_scalar)\n",
        "        v_out = self.vector_mlp(x_vector)\n",
        "        return s_out, v_out\n",
        "\n",
        "# == Full GVP Model ==\n",
        "class PowerfulGVPModel(nn.Module):\n",
        "    def __init__(self, scalar_dim=4, vector_dim=4, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.gvp1 = GVPBlock(scalar_dim, vector_dim, hidden_dim)\n",
        "        self.gvp2 = GVPBlock(hidden_dim, hidden_dim, hidden_dim)\n",
        "        self.gvp3 = GVPBlock(hidden_dim, hidden_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, 3)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x.float()\n",
        "        x_scalar = x[:, :4]\n",
        "        x_vector = x[:, 4:]\n",
        "\n",
        "        s, v = self.gvp1(x_scalar, x_vector)\n",
        "        s, v = self.gvp2(s, v)\n",
        "        s, v = self.gvp3(s, v)\n",
        "\n",
        "        x_combined = s + v\n",
        "        out = self.fc(x_combined)\n",
        "        return out\n",
        "\n",
        "# == Training ==\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = PowerfulGVPModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "best_loss = float('inf')\n",
        "patience = 10\n",
        "no_improve = 0\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(batch)\n",
        "        loss = loss_fn(pred, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch}: Train Loss = {avg_loss:.6f}\")\n",
        "\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        no_improve = 0\n",
        "        torch.save(model.state_dict(), \"best_gvp_model.pth\")\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        if no_improve >= patience:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "# == Evaluation ==\n",
        "model.load_state_dict(torch.load(\"best_gvp_model.pth\"))\n",
        "model.eval()\n",
        "predictions, targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(batch)\n",
        "        predictions.append(pred.cpu().numpy())\n",
        "        targets.append(batch.y.cpu().numpy())\n",
        "\n",
        "predictions = np.concatenate(predictions)\n",
        "targets = np.concatenate(targets)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(targets, predictions))\n",
        "mae = mean_absolute_error(targets, predictions)\n",
        "\n",
        "def calculate_tm_score(true, pred):\n",
        "    d = np.linalg.norm(true - pred, axis=1)\n",
        "    return np.mean(np.exp(-d / (0.5 * len(d))))\n",
        "\n",
        "tm_score = calculate_tm_score(targets, predictions)\n",
        "print(f\"\\nValidation Results:\\nRMSE = {rmse:.4f}, MAE = {mae:.4f}, TM-Score = {tm_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "f2pYsI9JQ3kT",
        "outputId": "9a2a5d23-7853-4041-d964-56851e5eb4f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 747/747 [03:23<00:00,  3.67it/s]\n",
            "100%|██████████| 83/83 [00:30<00:00,  2.69it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss = 0.947850\n",
            "Epoch 1: Train Loss = 0.947782\n",
            "Epoch 2: Train Loss = 0.947724\n",
            "Epoch 3: Train Loss = 0.947745\n",
            "Epoch 4: Train Loss = 0.947692\n",
            "Epoch 5: Train Loss = 0.947705\n",
            "Epoch 6: Train Loss = 0.947678\n",
            "Epoch 7: Train Loss = 0.947668\n",
            "Epoch 8: Train Loss = 0.947661\n",
            "Epoch 9: Train Loss = 0.947675\n",
            "Epoch 10: Train Loss = 0.947646\n",
            "Epoch 11: Train Loss = 0.947617\n",
            "Epoch 12: Train Loss = 0.947606\n",
            "Epoch 13: Train Loss = 0.947662\n",
            "Epoch 14: Train Loss = 0.947625\n",
            "Epoch 15: Train Loss = 0.947601\n",
            "Epoch 16: Train Loss = 0.947591\n",
            "Epoch 17: Train Loss = 0.947593\n",
            "Epoch 18: Train Loss = 0.947586\n",
            "Epoch 19: Train Loss = 0.947578\n",
            "Epoch 20: Train Loss = 0.947577\n",
            "Epoch 21: Train Loss = 0.947572\n",
            "Epoch 22: Train Loss = 0.947568\n",
            "Epoch 23: Train Loss = 0.947601\n",
            "Epoch 24: Train Loss = 0.947578\n",
            "Epoch 25: Train Loss = 0.947569\n",
            "Epoch 26: Train Loss = 0.947565\n",
            "Epoch 27: Train Loss = 0.947565\n",
            "Epoch 28: Train Loss = 0.947565\n",
            "Epoch 29: Train Loss = 0.947567\n",
            "Epoch 30: Train Loss = 0.947559\n",
            "Epoch 31: Train Loss = 0.947558\n",
            "Epoch 32: Train Loss = 0.947561\n",
            "Epoch 33: Train Loss = 0.947560\n",
            "Epoch 34: Train Loss = 0.947556\n",
            "Epoch 35: Train Loss = 0.947556\n",
            "Epoch 36: Train Loss = 0.947558\n",
            "Epoch 37: Train Loss = 0.947557\n",
            "Epoch 38: Train Loss = 0.947555\n",
            "Epoch 39: Train Loss = 0.947554\n",
            "Epoch 40: Train Loss = 0.947556\n",
            "Epoch 41: Train Loss = 0.947555\n",
            "Epoch 42: Train Loss = 0.947553\n",
            "Epoch 43: Train Loss = 0.947554\n",
            "Epoch 44: Train Loss = 0.947553\n",
            "Epoch 45: Train Loss = 0.947573\n",
            "Epoch 46: Train Loss = 0.947551\n",
            "Epoch 47: Train Loss = 0.947547\n",
            "Epoch 48: Train Loss = 0.947620\n",
            "Epoch 49: Train Loss = 0.947567\n",
            "Epoch 50: Train Loss = 0.947559\n",
            "Epoch 51: Train Loss = 0.947552\n",
            "Epoch 52: Train Loss = 0.947554\n",
            "Epoch 53: Train Loss = 0.947547\n",
            "Epoch 54: Train Loss = 0.947546\n",
            "Epoch 55: Train Loss = 0.947555\n",
            "Epoch 56: Train Loss = 0.947546\n",
            "Epoch 57: Train Loss = 0.947542\n",
            "Epoch 58: Train Loss = 0.947545\n",
            "Epoch 59: Train Loss = 0.947545\n",
            "Epoch 60: Train Loss = 0.947544\n",
            "Epoch 61: Train Loss = 0.947539\n",
            "Epoch 62: Train Loss = 0.947541\n",
            "Epoch 63: Train Loss = 0.947546\n",
            "Epoch 64: Train Loss = 0.947541\n",
            "Epoch 65: Train Loss = 0.947540\n",
            "Epoch 66: Train Loss = 0.947538\n",
            "Epoch 67: Train Loss = 0.947539\n",
            "Epoch 68: Train Loss = 0.947541\n",
            "Epoch 69: Train Loss = 0.947538\n",
            "Epoch 70: Train Loss = 0.947536\n",
            "Epoch 71: Train Loss = 0.947537\n",
            "Epoch 72: Train Loss = 0.947540\n",
            "Epoch 73: Train Loss = 0.947537\n",
            "Epoch 74: Train Loss = 0.947535\n",
            "Epoch 75: Train Loss = 0.947536\n",
            "Epoch 76: Train Loss = 0.947539\n",
            "Epoch 77: Train Loss = 0.947536\n",
            "Epoch 78: Train Loss = 0.947535\n",
            "Epoch 79: Train Loss = 0.947534\n",
            "Epoch 80: Train Loss = 0.947537\n",
            "Epoch 81: Train Loss = 0.947535\n",
            "Epoch 82: Train Loss = 0.947535\n",
            "Epoch 83: Train Loss = 0.947545\n",
            "Epoch 84: Train Loss = 0.947535\n",
            "Epoch 85: Train Loss = 0.947532\n",
            "Epoch 86: Train Loss = 0.947532\n",
            "Epoch 87: Train Loss = 0.947534\n",
            "Epoch 88: Train Loss = 0.947535\n",
            "Epoch 89: Train Loss = 0.947533\n",
            "Epoch 90: Train Loss = 0.947534\n",
            "Epoch 91: Train Loss = 0.947534\n",
            "Epoch 92: Train Loss = 0.947564\n",
            "Epoch 93: Train Loss = 0.947533\n",
            "Epoch 94: Train Loss = 0.947529\n",
            "Epoch 95: Train Loss = 0.947531\n",
            "Epoch 96: Train Loss = 0.947534\n",
            "Epoch 97: Train Loss = 0.947529\n",
            "Epoch 98: Train Loss = 0.947532\n",
            "Epoch 99: Train Loss = 0.947531\n",
            "\n",
            "Validation Results:\n",
            "RMSE = 27.4652, MAE = 21.3270, TM-Score = 0.9950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib"
      ],
      "metadata": {
        "id": "y-vo6JXeUQPj",
        "outputId": "6d4cad75-a42c-4855-d8fb-67e0c9e65cf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yOGektnDUjC9",
        "outputId": "53e594d9-fee2-4ca1-b2f3-08aa1a571cd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Then save it to your drive\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/GVP_Model.pth')\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/GVP_Scaler.save')\n",
        "\n",
        "print(\"Saved to Google Drive as 'GVP_Model.pth'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxJQGVM-TT1n",
        "outputId": "a9554c22-705f-4427-8245-47b2507f54b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to Google Drive as 'GVP_Model.pth'\n"
          ]
        }
      ]
    }
  ]
}